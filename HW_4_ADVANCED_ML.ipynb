{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import everygrams\n",
    "\n",
    "import re\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "POSSIBLE_CHARS = 'абвгдежзийклмнопрстуфхцчшщъыьэюя '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpora/WarAndPeace.txt', 'r') as file:\n",
    "    corpus_war_and_peace = file.readlines()\n",
    "\n",
    "with open('corpora/AnnaKarenina.txt' ,'r') as file:\n",
    "    corpus_karenina = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_karenina + corpus_war_and_peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['– Да, – сказал Левин медленно и взволнованно. – Ты прав, я дик. Но только дикость моя не в том, что я уехал, а в том, что я теперь приехал. Теперь я приехал.\\n',\n",
       " '\\n',\n",
       " '– О, какой ты счастливец! – подхватил Степан Аркадьич, глядя в глаза Левину.\\n',\n",
       " '\\n',\n",
       " '– Отчего?\\n',\n",
       " '\\n',\n",
       " '– Узнаю коней ретивых по каким-то их таврам[47], юношей влюбленных узнаю по их глазам, – продекламировал Степан Аркадьич. – У тебя все впереди.\\n',\n",
       " '\\n',\n",
       " '– А у тебя разве уж назади?\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer=tokenizer):\n",
    "    text = text.lower()\n",
    "    res = []\n",
    "    for symbol in text:\n",
    "        if symbol in POSSIBLE_CHARS:\n",
    "            res.append(symbol)\n",
    "    text = ''.join(res)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    \n",
    "    return ' '.join(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freqs(text, n_gram=1, min_freq=0):\n",
    "    \n",
    "    if n_gram > 1:\n",
    "        text = [''.join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)]\n",
    "        \n",
    "    res = {}\n",
    "    counter_text = Counter(text)\n",
    "    \n",
    "    for key, value in counter_text.items():\n",
    "        if value / len(text) > min_freq:\n",
    "            res[key] = value / len(text)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokenized = tokenize(' '.join(corpus))\n",
    "freqs = calc_freqs(corpus_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(freqs.keys())\n",
    "\n",
    "replacements = np.random.choice(words, replace=False, size=(len(freqs, )))\n",
    "\n",
    "char2replace = {}\n",
    "\n",
    "for origin, replace in zip(chars, replacements):\n",
    "    char2replace[origin] = replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_mapping(corpus_freqs, text_freqs):\n",
    "    \n",
    "    # get ranks\n",
    "    corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    reverse_dict = {}\n",
    "    for text_char, text_freq in text_freqs_sorted:\n",
    "        min_diff = 1\n",
    "        best_char = None\n",
    "        for corpus_char, corpus_freq in corpus_freqs_sorted:\n",
    "            diff = abs(corpus_freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_char = corpus_char\n",
    "                min_diff = diff\n",
    "\n",
    "        reverse_dict[text_char] = best_char\n",
    "        corpus_freqs_sorted = [(char, freq) for char, freq in corpus_freqs_sorted if char != best_char]\n",
    "        \n",
    "    return reverse_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_with_chars(text1, text2):\n",
    "    intersection = 0\n",
    "    \n",
    "    assert len(text1) == len(text2)\n",
    "    \n",
    "    for c1, c2 in zip(text1, text2):\n",
    "        if c1 == c2:\n",
    "            intersection += 1\n",
    "    return intersection / len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ['— Леди и джентльмены, — прозвучал голос из радиоприемника — четкий, спокойно-неумолимый мужской голос, совсем непохожий на те, что звучали в эфире уже много лет, — мистер Томпсон сегодня не будет говорить с вами. Его время истекло. С этого момента время принадлежит мне. Вы собирались выслушать сообщение о глобальном кризисе. Именно его вы сейчас и выслушаете. Три человека одновременно ахнули, узнав этот голос, но в криках толпы никто уже не мог услышать их, потому что крики толпы были оглушительны. Один из негромких возгласов выражал торжество, другой ужас, третий изумление. Три человека узнали говорившего: Дэгни, доктор Стадлер и Эдди Виллерс. Никто не смотрел на Эдди Виллерса, но Дэгни и доктор Стадлер посмотрели друг на друга. Она увидела, что его лицо исказилось от нестерпимого страха, он понял, что она знает и что она смотрит на него так, будто этот спокойный голос ударил его по лицу.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['— Леди и джентльмены, — прозвучал голос из радиоприемника — четкий, спокойно-неумолимый мужской голос, совсем непохожий на те, что звучали в эфире уже много лет, — мистер Томпсон сегодня не будет говорить с вами. Его время истекло. С этого момента время принадлежит мне. Вы собирались выслушать сообщение о глобальном кризисе. Именно его вы сейчас и выслушаете. Три человека одновременно ахнули, узнав этот голос, но в криках толпы никто уже не мог услышать их, потому что крики толпы были оглушительны. Один из негромких возгласов выражал торжество, другой ужас, третий изумление. Три человека узнали говорившего: Дэгни, доктор Стадлер и Эдди Виллерс. Никто не смотрел на Эдди Виллерса, но Дэгни и доктор Стадлер посмотрели друг на друга. Она увидела, что его лицо исказилось от нестерпимого страха, он понял, что она знает и что она смотрит на него так, будто этот спокойный голос ударил его по лицу.']\n"
     ]
    }
   ],
   "source": [
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenize(' '.join(sample_text))\n",
    "\n",
    "encoded_text = ''.join([char2replace.get(c, 'ь') for c in tokenized_text])\n",
    "text_freqs = calc_freqs(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "леди и джентльмены прозвучал голос из радиоприемника четкий спокойнонеумолимый мужской голос совсем непохожий на те что звучали в эфире уже много лет мистер томпсон сегодня не будет говорить с вами его время истекло с этого момента время принадлежит мне вы собирались выслушать сообщение о глобальном кризисе именно его вы сейчас и выслушаете три человека одновременно ахнули узнав этот голос но в криках толпы никто уже не мог услышать их потому что крики толпы были оглушительны один из негромких возгласов выражал торжество другой ужас третий изумление три человека узнали говорившего дэгни доктор стадлер и эдди виллерс никто не смотрел на эдди виллерса но дэгни и доктор стадлер посмотрели друг на друга она увидела что его лицо исказилось от нестерпимого страха он понял что она знает и что она смотрит на него так будто этот спокойный голос ударил его по лицу\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'и': 0.050808314087759814, 'ь': 0.06928406466512702, 'л': 0.02771362586605081, 'ч': 0.07043879907621248, 'я': 0.15935334872979215, 'д': 0.010392609699769052, 'ж': 0.05542725173210162, 'с': 0.057736720554272515, 'щ': 0.009237875288683603, 'з': 0.03002309468822171, 'ю': 0.015011547344110854, 'р': 0.016166281755196306, 'а': 0.04157043879907621, 'т': 0.10969976905311778, 'ш': 0.012702078521939953, 'б': 0.03002309468822171, 'э': 0.02771362586605081, 'в': 0.012702078521939953, 'ы': 0.04734411085450346, 'ф': 0.03002309468822171, 'х': 0.04387990762124711, ' ': 0.023094688221709007, 'н': 0.011547344110854504, 'й': 0.006928406466512702, 'г': 0.009237875288683603, 'м': 0.0011547344110854503, 'е': 0.004618937644341801, 'о': 0.006928406466512702, 'у': 0.005773672055427252, 'п': 0.0011547344110854503, 'к': 0.0023094688221709007}\n"
     ]
    }
   ],
   "source": [
    "print(text_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "иьлчячялдьжсищзьжюяратшбэвыияфтитхячшяаылчтрачьзжч ыявьс чняхрт тнжтжьэзтичзюнязэдх тняфтитхяхтбхьзяжьртйтдчняжыясьявстяшбэвыичябягмчаьяэдьязжтфтяиьсязчхсьаястзрхтжяхьфтлжеяжьяоэльсяфтбтачсщяхябызчяьфтябаьзеячхсь итяхягстфтязтзьжсыябаьзеярачжылиьдчсязжьябюяхточаыичхщябюхиэуысщяхттопьжчьятяфитоыищжтзя ачшчхьячзьжжтяьфтябюяхьнвыхячябюхиэуыьсьясачявьитбь ыятлжтбаьзьжжтяыйжэичяэшжыбягстсяфтитхяжтябя ач ыйястирюяжч стяэдьяжьязтфяэхиюуысщячйяртстзэявстя ач чястирюяоюичятфиэучсьищжюятлчжячшяжьфатз чйябтшфиыхтбябюаыдыиястадьхсбтялаэфтняэдыхясаьсчнячшэзиьжчьясачявьитбь ыяэшжыичяфтбтачбуьфтялгфжчялт стаяхсылиьаячягллчябчииьахяжч стяжьяхзтсаьияжыягллчябчииьахыяжтялгфжчячялт стаяхсылиьаяртхзтсаьичялаэфяжыялаэфыятжыяэбчльиыявстяьфтяичктячх ышчитхщятсяжьхсьарчзтфтяхсаыйыятжяртжеиявстятжыяшжыьсячявстятжыяхзтсачсяжыяжьфтясы яоэлстягстсяхрт тнжюняфтитхяэлыачияьфтяртяичкэ\n"
     ]
    }
   ],
   "source": [
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = get_reverse_mapping(freqs, text_freqs)\n",
    "decoded_text = ''.join([reverse_mapping.get(c, 'ь') for c in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'таме е мйаинтшкаиб ьвочрузст дотол еч всмеоьвеакиепс занпеж льопожиоиаукотекбж куйлпож дотол лорлак иаьоюойеж ис на зно чрузсте р хъева уйа киодо тан келнав нокьлои ладомищ иа эуман доровенш л рске адо рвакщ елнапто л хнодо кокаинс рвакщ ьвеисмтайен киа рб лоэевстелш рблтуцснш лооэыаиеа о дтоэстшиок пвечела екаиио адо рб лажзсл е рблтуцсана нве заторапс омиорвакаиио сюиуте учиср хнон дотол ио р пвепсю нотьб иепно уйа иа код ултбцснш ею ьоноку зно пвепе нотьб эбте одтуценатшиб омеи еч иадвокпею рочдтслор рбвсйст новйалнро мвудож уйсл нванеж ечуктаиеа нве заторапс учисте дороверцадо мхдие мопнов лнсмтав е хмме реттавл иепно иа лконват ис хмме реттавлс ио мхдие е мопнов лнсмтав ьолконвате мвуд ис мвудс оис урематс зно адо тефо елпсчетолш он иалнавьекодо лнвсюс ои ьоищт зно оис чисан е зно оис лконвен ис иадо нсп эумно хнон льопожибж дотол умсвет адо ьо тефу'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2967667436489607"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_with_chars(decoded_text, tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 30% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_mapping_for_bigram(corpus_freqs, text_freqs, init_mapping=None):\n",
    "\n",
    "    if not init_mapping:\n",
    "        init_mapping = []\n",
    "    reverse_mapping = {k: v for k, v in init_mapping}\n",
    "    \n",
    "    corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    \n",
    "    for i, (text_bigram, text_freq) in enumerate(text_freqs_sorted):\n",
    "\n",
    "        filtred_freqs = copy(corpus_freqs_sorted)\n",
    "        \n",
    "        if text_bigram[0] in reverse_mapping.keys():\n",
    "            filtred_freqs = [(bigram, freq) for bigram, freq in filtred_freqs if bigram[0] == reverse_mapping[text_bigram[0]]]\n",
    "            \n",
    "        if text_bigram[1] in reverse_mapping.keys():\n",
    "            filtred_freqs = [(bigram, freq) for bigram, freq in filtred_freqs if bigram[1] == reverse_mapping[text_bigram[1]]]\n",
    "              \n",
    "        min_diff = 1\n",
    "        best_bigram = None\n",
    "        for bigram, freq in filtred_freqs:\n",
    "            diff = abs(freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_bigram = bigram\n",
    "                min_diff = diff\n",
    "                \n",
    "        if text_bigram[0] not in reverse_mapping.keys():\n",
    "            reverse_mapping[text_bigram[0]] = best_bigram[0]\n",
    "            \n",
    "        if text_bigram[1] not in reverse_mapping.keys():\n",
    "            reverse_mapping[text_bigram[1]] = best_bigram[1]\n",
    "\n",
    "        \n",
    "    return reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_freqs_bigram = calc_freqs(corpus_tokenized, n_gram=2)\n",
    "text_freqs_bigram = calc_freqs(encoded_text, n_gram=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping_bigram = get_reverse_mapping_for_bigram(corpus_freqs_bigram, text_freqs_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = ''.join([reverse_mapping_bigram.get(c, 'ь') for c in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "няко о ксястнвпясм п огвккен тонос ог  екооп ояпсоле кятлол спололсосякпонопмл пксслол тонос совсяп сяпогосол се тя кто гвккено в бро я кся псото нят постя  топпсос сятоксю ся лккят тово отв с вепо ято в япю остялно с бтото попясте в япю п осекнясот пся вм соло еносв вмснкиетв соолуясоя о тноленвсоп л огося опяссо ято вм сялкес о вмснкиеятя т о кяновяле оксов япяссо егскно кгсев бтот тонос со в л олег тонпм солто кся ся пот кснмиетв ог потопк кто л оло тонпм лмно отнкиотянвсм окос ог сят оплог вогтнесов вм есен то сяство к ктол ксес т ятол огкпнясоя т о кяновяле кгсено тово овиято кбтсо колто  стекня  о бкко воння с солто ся спот ян се бкко воння се со кбтсо о колто  стекня  поспот яно к кт се к кте осе квокяне кто ято ноео ослегоносв от сястя попото ст еге ос посюн кто осе гсеят о кто осе спот от се сято тел лккто бтот спололсмл тонос кке он ято по ноек\n"
     ]
    }
   ],
   "source": [
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4168591224018476"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_with_chars(decoded_text, tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 40 % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC sampling with bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "enumerate_chars = {c: i for i, c in enumerate(POSSIBLE_CHARS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions_matrix(text, matrix_of_transitions):\n",
    "    for i in range(len(text)-1):\n",
    "        matrix_of_transitions[enumerate_chars[text[i]], enumerate_chars[text[i+1]]] += 1\n",
    "    matrix_of_transitions = np.clip(matrix_of_transitions, 1, None)\n",
    "    matrix_of_transitions = (np.log(matrix_of_transitions).T - np.log(matrix_of_transitions.sum(axis=1))).T\n",
    "    return matrix_of_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood(text, permutation):\n",
    "    text = text.translate(str.maketrans(POSSIBLE_CHARS, ''.join(permutation)))\n",
    "    return sum([matrix_of_transitions[enumerate_chars[text[i]], enumerate_chars[text[i+1]]] for i in range(len(text) - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def decode_mcmc(text, iterations=10000):\n",
    "    permutation = np.array(list(POSSIBLE_CHARS))\n",
    "    random.shuffle(permutation)\n",
    "    log_likelihood = calculate_log_likelihood(text, permutation)\n",
    "    \n",
    "    log_likelihood_best = log_likelihood\n",
    "    permutation_best = permutation.copy()\n",
    "    \n",
    "    for i in tqdm(range(iterations)):\n",
    "        swap = random.sample(range(len(POSSIBLE_CHARS)), 2)\n",
    "        permutation[swap[0]], permutation[swap[1]] = permutation[swap[1]], permutation[swap[0]]\n",
    "        log_likelihood_new = calculate_log_likelihood(text, permutation)\n",
    "        if log_likelihood_new >= log_likelihood:\n",
    "            log_likelihood = log_likelihood_new\n",
    "            if log_likelihood_new > log_likelihood_best:\n",
    "                log_likelihood_best = log_likelihood_new\n",
    "                permutation_best = permutation.copy()\n",
    "        else:\n",
    "            if random.random() < np.exp(log_likelihood_new - log_likelihood):\n",
    "                log_likelihood = log_likelihood_new\n",
    "            else:\n",
    "                permutation[swap[0]], permutation[swap[1]] = permutation[swap[1]], permutation[swap[0]]\n",
    "    return text.translate(str.maketrans(POSSIBLE_CHARS, ''.join(permutation_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:57<00:00, 1751.55it/s]\n"
     ]
    }
   ],
   "source": [
    "matrix_of_transitions = get_transitions_matrix(corpus_tokenized, np.zeros((len(POSSIBLE_CHARS), len(POSSIBLE_CHARS))))\n",
    "decoded = decode_mcmc(tokenized_text, 100000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_with_chars(decoded, tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bingo !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode weird encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "message = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'\n",
    "encoded_characters = ''.join(set(message))\n",
    "print(len(set(encoded_characters)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_freq = sorted(list(freqs.items()), key=lambda x: x[1], reverse=True)\n",
    "top_freq_chars = [x[0] for x in top_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' оеанитслвркдмупяьгыбзчжйшхю'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_top_frequent_chars = ''.join(top_freq_chars)[:len(set(message))]\n",
    "rus_top_frequent_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_part = str.maketrans(encoded_characters, rus_top_frequent_chars)\n",
    "message = message.translate(russian_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сраьгпигпьуьбсгялхотадяиыгьаьгмл бьгялхотадяиыгбснрбгйгшблюлгрллжесяьзгнлблхиыгасюнлгмхл ьбтбдгрнлхссгпрсюлгпигпрсгрусатаьгмхтпьадялгьгмлай ьбсготнрьотадяиыгжтаагчтгмлрасуяссг сбпсхблсгчтутяьсгнйхртгклбзгнляс ялгзгяь сюлгясглжсетв\n"
     ]
    }
   ],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:16<00:00, 5933.33it/s]\n"
     ]
    }
   ],
   "source": [
    "decoded = decode_mcmc(message, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
